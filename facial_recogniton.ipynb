{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adf0a3f",
   "metadata": {},
   "source": [
    "# Facial Recognition Pipeline\n",
    "\n",
    "This project implements a facial recognition system that identifies faces by converting them into **128-dimensional vector embeddings**. Faces belonging to the same person should produce embeddings that are close together, while embeddings from different people should be farther apart. A simple classifier (like **KNN** or **SVM**) then maps these embeddings to identities.\n",
    "\n",
    "![Facial Recognition Pipeline](./examples/fast-five-1200-1200-675-675-crop-000000.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11579683",
   "metadata": {},
   "source": [
    "First, we need to install the required libraries. You can do this by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "pip install face_recognition opencv-python scikit-learn imutils icrawler dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15204dbe",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this facial recognition project, we'll create a custom dataset of **Fast & Furious** actors. The dataset will include images of 10 main characters from the franchise:\n",
    "\n",
    "- **Vin Diesel** (Dominic Toretto)\n",
    "- **Paul Walker** (Brian O'Conner) \n",
    "- **Dwayne Johnson** (Luke Hobbs)\n",
    "- **Michelle Rodriguez** (Letty Ortiz)\n",
    "- **Tyrese Gibson** (Roman Pearce)\n",
    "- **Ludacris** (Tej Parker)\n",
    "- **Jordana Brewster** (Mia Toretto)\n",
    "- **Gal Gadot** (Gisele Yashar)\n",
    "- **Sung Kang** (Han Seoul-Oh)\n",
    "- **Jason Statham** (Deckard Shaw)\n",
    "\n",
    "### Dataset Structure\n",
    "```\n",
    "dataset/\n",
    "├── Vin_Diesel/\n",
    "│   ├── 000001.jpg\n",
    "│   ├── 000002.jpg\n",
    "│   └── ... (30 images)\n",
    "├── Paul_Walker/\n",
    "│   ├── 000001.jpg\n",
    "│   └── ... (30 images)\n",
    "└── ... (other actors)\n",
    "```\n",
    "\n",
    "### Data Collection\n",
    "We'll automatically download **30 images per actor** from Google Images using the `icrawler` library. This provides us with a diverse set of facial images for training our recognition model. The images will be stored in separate folders for each actor, making it easy to extract labels during the encoding process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6469c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 18:57:49,364 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-16 18:57:49,365 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-16 18:57:49,366 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-16 18:57:49,366 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-16 18:57:49,368 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2025-09-16 18:57:50,765 - INFO - parser - parsing result page https://www.google.com/search?q=Tyrese+Gibson+photoshoot&ijn=0&start=0&tbs=&tbm=isch\n",
      "2025-09-16 18:57:51,591 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1753355588/photo/tyrese-promotional-visit-in-chicago.jpg\n",
      "2025-09-16 18:57:51,946 - INFO - downloader - image #1\thttps://i.pinimg.com/564x/4e/89/9e/4e899eb774d5643c62fc434216357efb.jpg\n",
      "2025-09-16 18:57:52,162 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1753354998/photo/singer-tyrese-poses-for-photos-during-a-break-in-his-work-out-while-attending-the-midwest.jpg\n",
      "2025-09-16 18:57:52,883 - INFO - downloader - image #2\thttps://pbs.twimg.com/profile_images/1757500511039930368/ZiaOUaY4_400x400.jpg\n",
      "2025-09-16 18:57:53,146 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/541234728/photo/tyrese.jpg\n",
      "2025-09-16 18:57:54,183 - INFO - downloader - image #3\thttps://www.hollywoodreporter.com/wp-content/uploads/2018/05/tyrese_gibson.jpg\n",
      "2025-09-16 18:57:54,442 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/541234752/photo/tyrese-singing.jpg\n",
      "2025-09-16 18:57:54,893 - INFO - downloader - image #4\thttps://i.pinimg.com/736x/7b/f5/d0/7bf5d07ba8fa0202673d68f9c71f32d2.jpg\n",
      "2025-09-16 18:57:55,153 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/540782486/photo/tyrese.jpg\n",
      "2025-09-16 18:57:55,230 - INFO - downloader - image #5\thttps://resizing.flixster.com/6LC63lz0jVoLB5rUyJ0k54NHfuk=/fit-in/705x460/v2/https://resizing.flixster.com/-XZAfHZM39UwaGJIFWKAE8fS0ak=/v3/t/assets/200301_v9_bc.jpg\n",
      "2025-09-16 18:57:55,506 - INFO - downloader - image #6\thttps://i.pinimg.com/736x/a9/13/74/a913746d30c87ae81d4651f0d2e5a468.jpg\n",
      "2025-09-16 18:57:56,880 - INFO - downloader - image #7\thttps://www.aceshowbiz.com/images/photo/tyrese_gibson.jpg\n",
      "2025-09-16 18:57:57,090 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/541234740/photo/tyrese.jpg\n",
      "2025-09-16 18:57:57,436 - ERROR - downloader - Response status code 400, file https://cdn.myportfolio.com/133b591eb5451055133bfd566c4e3a16/2ad125acc95e5d0de3f689b0_rw_1920.jpg\n",
      "2025-09-16 18:57:57,738 - INFO - downloader - image #8\thttps://i.pinimg.com/474x/c5/15/5c/c5155cdf3fd2403f8ad1151d484f592f.jpg\n",
      "2025-09-16 18:57:58,114 - INFO - downloader - image #9\thttps://i.ebayimg.com/images/g/rV0AAOSw~2Jkej-0/s-l1200.jpg\n",
      "2025-09-16 18:57:58,331 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/71706646/photo/los-angeles-ca-actor-tyrese-gibson-talks-at-the-four-seasons-hotel-on-june-10-2006-in-los.jpg\n",
      "2025-09-16 18:57:58,726 - ERROR - downloader - Response status code 403, file https://i.redd.it/tyrese-gibson-actor-v0-cju4tdq517da1.jpg\n",
      "2025-09-16 18:57:58,814 - INFO - downloader - image #10\thttps://www.shutterstock.com/image-photo/los-angeles-oct-24-tyrese-260nw-503930083.jpg\n",
      "2025-09-16 18:57:59,494 - ERROR - downloader - Response status code 404, file https://images.fandango.com/ImageRenderer/400/0/redesign/static/img/default_poster.png\n",
      "2025-09-16 18:58:00,907 - INFO - downloader - image #11\thttps://www.bellanaija.com/wp-content/uploads/2017/02/tyrese.jpg\n",
      "2025-09-16 18:58:01,373 - INFO - downloader - image #12\thttps://resizing.flixster.com/5vmdEqgwA6kKFYLYVBZFf5APbm4=/fit-in/705x460/v2/https://resizing.flixster.com/-XZAfHZM39UwaGJIFWKAE8fS0ak=/v3/t/v9/AllPhotos/200301/200301_v9_bb.jpg\n",
      "2025-09-16 18:58:01,706 - INFO - downloader - image #13\thttps://i.pinimg.com/736x/53/93/af/5393afe70958083d03573bc7cb53cd63.jpg\n",
      "2025-09-16 18:58:01,978 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1473144728/photo/beverly-hills-california-tyrese-gibson-attends-the-2023-vanity-fair-oscar-party-hosted-by.jpg\n",
      "2025-09-16 18:58:02,220 - INFO - downloader - image #14\thttps://i.pinimg.com/736x/8c/77/76/8c777672fa5e6053a8f5ad59abc6e0a5.jpg\n",
      "2025-09-16 18:58:03,904 - INFO - downloader - image #15\thttp://www.kiwithebeauty.com/wp-content/uploads/2015/04/tyrese-gibson-2015.jpg\n",
      "2025-09-16 18:58:05,375 - INFO - downloader - image #16\thttps://imageio.forbes.com/blogs-images/danschawbel/files/2013/02/217220_211747102186227_6123958_n-225x300.jpg\n",
      "2025-09-16 18:58:06,283 - INFO - downloader - image #17\thttps://assets.mycast.io/actor_images/actor-tyrese-gibson-762374_large.jpg\n",
      "2025-09-16 18:58:06,548 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/530647440/photo/rapper-tyrese-gibson-is-photographed-at-his-recording-studio-in-2007.jpg\n",
      "2025-09-16 18:58:06,825 - INFO - downloader - image #18\thttps://i.pinimg.com/originals/27/90/5a/27905a54af788315aa4055774ab5b960.jpg\n",
      "2025-09-16 18:58:08,026 - INFO - downloader - image #19\thttps://resizing.flixster.com/smebbLAlxd70tuoGepOT84o-WyE=/fit-in/705x460/v2/http://media.baselineresearch.com/images/1754050/1754050_full.jpg\n",
      "2025-09-16 18:58:08,290 - INFO - downloader - image #20\thttps://i.pinimg.com/originals/cb/d5/61/cbd56117848d4d1e7b93b4af99dd005a.jpg\n",
      "2025-09-16 18:58:08,589 - INFO - downloader - image #21\thttps://www.shutterstock.com/editorial/image-editorial/Nbz9k83eM9DfA549Mzc3/tyrese-gibson-1500w-793506f.jpg\n",
      "2025-09-16 18:58:10,218 - INFO - downloader - image #22\thttps://www.mm-group.org/wp-content/uploads/2016/07/10850106_1160547540639507_1740326242267126548_n.jpg\n",
      "2025-09-16 18:58:10,690 - INFO - downloader - image #23\thttps://m.media-amazon.com/images/M/MV5BYzc4MDA4MGQtM2VkMC00ZTdmLWJkOTYtODkzMDE0OTFlODEzXkEyXkFqcGc@._V1_.jpg\n",
      "2025-09-16 18:58:11,814 - INFO - downloader - image #24\thttps://img.pr.com/upload/article_attachment_1165712374.jpg\n",
      "2025-09-16 18:58:12,957 - INFO - downloader - image #25\thttps://www.mm-group.org/wp-content/uploads/2016/07/PRN22-MBK-ENTERTAINMENT-GIBSON-1yHigh.jpg\n",
      "2025-09-16 18:58:14,336 - INFO - downloader - image #26\thttps://hollywoodlife.com/wp-content/uploads/2017/03/Tyrese-Gibson-1.jpg\n",
      "2025-09-16 18:58:19,307 - INFO - downloader - image #27\thttps://singersroom.com/wp-content/uploads/2016/01/tyrese_6.jpg\n",
      "2025-09-16 18:58:19,567 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1870769665/photo/american-singer-and-actor-tyrese-in-october-2001-in-temecula-california.jpg\n",
      "2025-09-16 18:58:20,287 - INFO - downloader - image #28\thttps://cdn01.justjared.com/wp-content/uploads/headlines/2023/08/tyrese-gibson-sues-home-depot.jpg\n",
      "2025-09-16 18:58:21,825 - INFO - downloader - image #29\thttps://resizing.flixster.com/GH0Oty9jfO5-t7-qmR6-J5L8sn0=/fit-in/705x460/v2/http://media.baselineresearch.com/images/237346/237346_full.jpg\n",
      "2025-09-16 18:58:22,311 - INFO - downloader - image #30\thttps://thumbs.dreamstime.com/b/tyrese-gibson-arriving-fast-furious-premiere-empire-leicester-square-london-picture-steve-vas-featureflash-31521499.jpg\n",
      "2025-09-16 18:58:23,714 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2025-09-16 18:58:23,716 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-16 18:58:24,314 - INFO - parser - downloaded image reached max num, thread parser-001 is ready to exit\n",
      "2025-09-16 18:58:24,315 - INFO - parser - thread parser-001 exit\n",
      "2025-09-16 18:58:24,401 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded images for Tyrese Gibson\n",
      "🎯 Dataset ready in 'dataset/'\n"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "import os\n",
    "\n",
    "actors = [\n",
    "    \"Tyrese Gibson\",\n",
    "]\n",
    "\n",
    "base_dir = \"dataset\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "def download_images(actor_name, max_images=30):\n",
    "    \"\"\"Download images of the actor from Google.\"\"\"\n",
    "    actor_dir = os.path.join(base_dir, actor_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(actor_dir, exist_ok=True)\n",
    "    \n",
    "    google_crawler = GoogleImageCrawler(storage={\"root_dir\": actor_dir})\n",
    "    google_crawler.crawl(keyword=actor_name + \" photoshoot\", max_num=max_images)\n",
    "    print(f\"✅ Downloaded images for {actor_name}\")\n",
    "\n",
    "# Download images for all actors\n",
    "for actor in actors:\n",
    "    download_images(actor, max_images=30)\n",
    "\n",
    "print(\"🎯 Dataset ready in 'dataset/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a20fcf",
   "metadata": {},
   "source": [
    "## 🚀 Overview of the Pipeline\n",
    "\n",
    "The system is divided into 4 main stages:\n",
    "\n",
    "### 1. Detecting Faces (HOG-based Detection)\n",
    "\n",
    "The first step is locating faces in images using **Histogram of Oriented Gradients (HOG)**. It’s an efficient algorithm that works well for frontal faces.\n",
    "\n",
    "#### How it works:\n",
    "\n",
    "- **1.1 Grayscale conversion:**  \n",
    "  Each image is first converted to grayscale to reduce computational complexity.\n",
    "\n",
    "- **1.2 Compute pixel gradients:**  \n",
    "  For every pixel, we calculate how dark it is compared to its immediate neighbors. This gives us a gradient vector showing the direction of intensity change.\n",
    "\n",
    "- **1.3 Aggregate gradient directions:**  \n",
    "  Since computing this for every pixel is too detailed, we divide the image into small cells (typically 16×16 pixels). For each cell, we count how many gradients point in each major direction (e.g., 0°, 45°, 90°, etc.) and summarize the cell with a dominant direction.\n",
    "\n",
    "- **1.4 Compare with face templates:**  \n",
    "  The final HOG representation is compared with a known HOG pattern for a face to determine whether a face is present and where it is.\n",
    "```python\n",
    "import face_recognition\n",
    "\n",
    "image = face_recognition.load_image_file(\"example.jpg\")\n",
    "face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "\n",
    "```\n",
    "This gives us bounding boxes for the detected faces.\n",
    "\n",
    "![HOG Detection Example](./assets/face_detection.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Aligning Faces (Facial Landmark Projection)\n",
    "\n",
    "Once we detect a face, we want to align it so that facial features (like eyes and mouth) are in consistent positions across all images. This is important for the encoder to generate meaningful embeddings.\n",
    "\n",
    "We do this by finding **68 facial landmarks** for each face and warping the image accordingly.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "* A pre-trained model predicts the coordinates of 68 key facial features.\n",
    "* We use these points to **rotate, scale, and warp** the face so it is centered and normalized in the frame.\n",
    "\n",
    "#### Landmark Detection Details:\n",
    "\n",
    "Landmark detection models are typically based on **regression trees** or **deep CNNs**. One well-known implementation is Dlib’s shape predictor, which was trained on labeled facial images to output consistent landmark coordinates. More advanced methods like **OpenFace** or **MediaPipe Face Mesh** use neural networks for more robust landmark estimation.\n",
    "\n",
    "```python\n",
    "import dlib\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "image_bgr = cv2.imread(\"./examples/fast-five-1200-1200-675-675-crop-000000.jpg\")\n",
    "gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "face_locations = face_recognition.face_locations(image_rgb, model=\"hog\")\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    face_rect = dlib.rectangle(left, top, right, bottom)\n",
    "    \n",
    "    landmarks = predictor(gray, face_rect)\n",
    "```\n",
    "![Facial Landmark Example](./assets/landmarks_result.jpg)\n",
    "---\n",
    "\n",
    "### 3. Encoding Faces (128-Dimensional Embedding)\n",
    "\n",
    "After alignment, each face is passed through a **deep convolutional neural network** to extract a 128-dimensional embedding vector.\n",
    "\n",
    "This vector is trained to capture the identity of the person in such a way that:\n",
    "\n",
    "* Embeddings of the **same person** have a small Euclidean distance.\n",
    "* Embeddings of **different people** are far apart.\n",
    "\n",
    "We use a pre-trained encoder (like the one provided by `face_recognition`, based on dlib and similar to OpenFace) to handle this step.\n",
    "\n",
    "```python\n",
    "face_encodings = face_recognition.face_encodings(image, known_face_locations=face_locations)\n",
    "```\n",
    "\n",
    "Each face encoding is just a NumPy array of 128 float values.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Classifying Faces (KNN / SVM)\n",
    "\n",
    "At this point, face recognition becomes a classification problem:\n",
    "\n",
    "* For each person in your dataset, compute and store their embeddings.\n",
    "* When a new image comes in, generate its embedding and **compare it** to the stored ones.\n",
    "\n",
    "We can use:\n",
    "\n",
    "* **K-Nearest Neighbors (KNN):**\n",
    "  A simple and effective method. Given a new embedding, find the k closest embeddings in the dataset and vote.\n",
    "\n",
    "* **Support Vector Machine (SVM):**\n",
    "  Useful when you want a trained decision boundary between classes.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(known_embeddings, known_labels)\n",
    "\n",
    "prediction = knn.predict([new_embedding])\n",
    "```\n",
    "![Classification Example](./assets/classification.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379b0fe",
   "metadata": {},
   "source": [
    "Let's implement the pipeline using out dataset of Fast & Furious actors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720ec1e",
   "metadata": {},
   "source": [
    "Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34885ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b787eb",
   "metadata": {},
   "source": [
    "Define our dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce0d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset\"\n",
    "encoding_path = \"./encodings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322dfd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(data_path))\n",
    "knownEncodings = []\n",
    "knownNames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6025b5c",
   "metadata": {},
   "source": [
    "Encode the faces using the `face_recognition` library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150bcb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/318\n",
      "Ludacris\n",
      "[INFO] processing image 2/318\n",
      "Ludacris\n",
      "[INFO] processing image 3/318\n",
      "Ludacris\n",
      "[INFO] processing image 4/318\n",
      "Ludacris\n",
      "[INFO] processing image 5/318\n",
      "Ludacris\n",
      "[INFO] processing image 6/318\n",
      "Ludacris\n",
      "[INFO] processing image 7/318\n",
      "Ludacris\n",
      "[INFO] processing image 8/318\n",
      "Ludacris\n",
      "[INFO] processing image 9/318\n",
      "Ludacris\n",
      "[INFO] processing image 10/318\n",
      "Ludacris\n",
      "[INFO] processing image 11/318\n",
      "Ludacris\n",
      "[INFO] processing image 12/318\n",
      "Ludacris\n",
      "[INFO] processing image 13/318\n",
      "Ludacris\n",
      "[INFO] processing image 14/318\n",
      "Ludacris\n",
      "[INFO] processing image 15/318\n",
      "Ludacris\n",
      "[INFO] processing image 16/318\n",
      "Ludacris\n",
      "[INFO] processing image 17/318\n",
      "Ludacris\n",
      "[INFO] processing image 18/318\n",
      "Ludacris\n",
      "[INFO] processing image 19/318\n",
      "Ludacris\n",
      "[INFO] processing image 20/318\n",
      "Ludacris\n",
      "[INFO] processing image 21/318\n",
      "Ludacris\n",
      "[INFO] processing image 22/318\n",
      "Ludacris\n",
      "[INFO] processing image 23/318\n",
      "Ludacris\n",
      "[INFO] processing image 24/318\n",
      "Ludacris\n",
      "[INFO] processing image 25/318\n",
      "Ludacris\n",
      "[INFO] processing image 26/318\n",
      "Ludacris\n",
      "[INFO] processing image 27/318\n",
      "Ludacris\n",
      "[INFO] processing image 28/318\n",
      "Ludacris\n",
      "[INFO] processing image 29/318\n",
      "Ludacris\n",
      "[INFO] processing image 30/318\n",
      "Ludacris\n",
      "[INFO] processing image 31/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 32/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 33/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 34/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 35/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 36/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 37/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 38/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 39/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 40/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 41/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 42/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 43/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 44/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 45/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 46/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 47/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 48/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 49/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 50/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 51/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 52/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 53/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 54/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 55/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 56/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 57/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 58/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 59/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 60/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 61/318\n",
      "Paul_Walker\n",
      "[INFO] processing image 62/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 63/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 64/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 65/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 66/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 67/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 68/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 69/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 70/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 71/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 72/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 73/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 74/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 75/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 76/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 77/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 78/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 79/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 80/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 81/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 82/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 83/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 84/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 85/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 86/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 87/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 88/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 89/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 90/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 91/318\n",
      "Tyrese_Gibson\n",
      "[INFO] processing image 92/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 93/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 94/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 95/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 96/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 97/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 98/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 99/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 100/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 101/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 102/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 103/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 104/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 105/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 106/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 107/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 108/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 109/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 110/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 111/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 112/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 113/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 114/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 115/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 116/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 117/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 118/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 119/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 120/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 121/318\n",
      "Gal_Gadot\n",
      "[INFO] processing image 122/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 123/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 124/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 125/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 126/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 127/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 128/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 129/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 130/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 131/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 132/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 133/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 134/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 135/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 136/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 137/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 138/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 139/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 140/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 141/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 142/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 143/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 144/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 145/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 146/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 147/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 148/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 149/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 150/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 151/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 152/318\n",
      "Sung_Kang\n",
      "[INFO] processing image 153/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 154/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 155/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 156/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 157/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 158/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 159/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 160/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 161/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 162/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 163/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 164/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 165/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 166/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 167/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 168/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 169/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 170/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 171/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 172/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 173/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 174/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 175/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 176/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 177/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 178/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 179/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 180/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 181/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 182/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 183/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 184/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 185/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 186/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 187/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 188/318\n",
      "Jordana_Brewster\n",
      "[INFO] processing image 189/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 190/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 191/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 192/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 193/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 194/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 195/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 196/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 197/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 198/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 199/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 200/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 201/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 202/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 203/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 204/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 205/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 206/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 207/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 208/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 209/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 210/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 211/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 212/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 213/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 214/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 215/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 216/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 217/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 218/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 219/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 220/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 221/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 222/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 223/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 224/318\n",
      "Dwayne_Johnson\n",
      "[INFO] processing image 225/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 226/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 227/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 228/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 229/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 230/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 231/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 232/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 233/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 234/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 235/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 236/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 237/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 238/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 239/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 240/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 241/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 242/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 243/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 244/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 245/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 246/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 247/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 248/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 249/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 250/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 251/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 252/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 253/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 254/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 255/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 256/318\n",
      "Vin_Diesel\n",
      "[INFO] processing image 257/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 258/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 259/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 260/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 261/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 262/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 263/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 264/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 265/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 266/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 267/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 268/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 269/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 270/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 271/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 272/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 273/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 274/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 275/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 276/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 277/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 278/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 279/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 280/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 281/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 282/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 283/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 284/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 285/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 286/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 287/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 288/318\n",
      "Jason_Statham\n",
      "[INFO] processing image 289/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 290/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 291/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 292/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 293/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 294/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 295/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 296/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 297/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 298/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 299/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 300/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 301/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 302/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 303/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 304/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 305/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 306/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 307/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 308/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 309/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 310/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 311/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 312/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 313/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 314/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 315/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 316/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 317/318\n",
      "Michelle_Rodriguez\n",
      "[INFO] processing image 318/318\n",
      "Michelle_Rodriguez\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "\t# extract the person name from the image path\n",
    "\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n",
    "\t\tlen(imagePaths)))\n",
    "\tname = imagePath.split(os.path.sep)[-2]\n",
    "\tprint(name)\n",
    "\t# load the input image and convert it from BGR (OpenCV ordering)\n",
    "\t# to dlib ordering (RGB)\n",
    "\timage = cv2.imread(imagePath)\n",
    "\trgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\tboxes = face_recognition.face_locations(rgb,\n",
    "\t\tmodel=\"hog\")\n",
    "\t# compute the facial embedding for the face\n",
    "\tencodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\t# loop over the encodings\n",
    "\tfor encoding in encodings:\n",
    "\t\t# add each encoding + name to our set of known names and\n",
    "\t\t# encodings\n",
    "\t\tknownEncodings.append(encoding)\n",
    "\t\tknownNames.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6c527",
   "metadata": {},
   "source": [
    "Save our embeddings and labels for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8ed582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Face encodings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "with open(encoding_path+\"/encoding.pkl\", \"wb\") as f:\n",
    "    f.write(pickle.dumps(data))\n",
    "print(\"[INFO] Face encodings saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849e49f",
   "metadata": {},
   "source": [
    "Now that we've encoded all the faces in our dataset, let's see how the recognition process works.\n",
    "\n",
    "#### 1. **Load Saved Encodings**\n",
    "```python\n",
    "data = pickle.loads(open(encoding_path+\"/encoding.pkl\", \"rb\").read())\n",
    "```\n",
    "We load our previously saved face encodings and corresponding names from the pickle file.\n",
    "\n",
    "#### 2. **Process Each Test Image**\n",
    "For every image in our `./examples/` folder:\n",
    "- **Load the image** using OpenCV\n",
    "- **Convert color space** from BGR to RGB (required by face_recognition library)\n",
    "- **Detect faces** using HOG-based detection\n",
    "- **Generate encodings** for detected faces\n",
    "\n",
    "#### 3. **Face Matching Algorithm**\n",
    "For each detected face encoding:\n",
    "\n",
    "**Step 3.1: Compare with Known Faces**\n",
    "```python\n",
    "matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "```\n",
    "This compares the current face encoding with all encodings in our dataset, returning a boolean list. The function calculates the Euclidean distance between the new face encoding and each of the known encodings in your list.\n",
    "\n",
    "**Step 3.2: Find Best Match Using Voting**\n",
    "```python\n",
    "if True in matches:\n",
    "    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "    counts = {}\n",
    "    for i in matchedIdxs:\n",
    "        name = data[\"names\"][i]\n",
    "        counts[name] = counts.get(name, 0) + 1\n",
    "    name = max(counts, key=counts.get)\n",
    "```\n",
    "\n",
    "This implements a **voting mechanism**:\n",
    "- Collect all matching face indices\n",
    "- Count votes for each person name\n",
    "- Select the name with the most votes (handles multiple encodings per person)\n",
    "\n",
    "\n",
    "This testing phase validates that our face recognition pipeline can successfully identify the Fast & Furious actors from new images not used during the encoding phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799fc96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names detected in ./examples/fast-five-1200-1200-675-675-crop-000000.jpg: ['Jordana_Brewster', 'Vin_Diesel', 'Paul_Walker', 'Gal_Gadot', 'Dwayne_Johnson']\n"
     ]
    }
   ],
   "source": [
    "data = pickle.loads(open(encoding_path+\"/encoding.pkl\", \"rb\").read())\n",
    "for imagePath in list(paths.list_images(\"./examples\")):\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    boxes = face_recognition.face_locations(rgb, model=\"hog\")\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    \n",
    "    names = []\n",
    "    for encoding in encodings:\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        name = \"Unknown\"\n",
    "        \n",
    "        if True in matches:\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            name = max(counts, key=counts.get)\n",
    "        \n",
    "        names.append(name)\n",
    "    print(f\"Names detected in {imagePath}: {names}\")\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.imwrite(f\"./output/{os.path.basename(imagePath)}\", image)\n",
    "    cv2.waitKey(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c471f",
   "metadata": {},
   "source": [
    "## 🎬 Real-Time Video Face Recognition\n",
    "\n",
    "Now let's apply our trained face recognition system to process video files. This demonstrates how the pipeline performs on moving images with multiple faces appearing and disappearing throughout the video.\n",
    "\n",
    "### Video Processing Features:\n",
    "\n",
    "- **Frame-by-frame analysis**: Process each video frame to detect and identify faces\n",
    "- **Optimized performance**: Skip frames to balance accuracy with processing speed\n",
    "- **Real-time display**: Show recognition results as the video plays\n",
    "- **Output generation**: Save processed video with face annotations\n",
    "- **Smooth tracking**: Use previous frame results for skipped frames to maintain consistency\n",
    "\n",
    "### Video Demo:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./assets/fast5.gif\" alt=\"Video Demo\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d495e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing video: .video/fast5-lq.mp4...\n",
      "[INFO] Video properties: FPS=0, Width=0, Height=0\n",
      "[INFO] cleaning up...\n",
      "[INFO] Output video saved to: ./output/video/output_fast5.mp4\n"
     ]
    }
   ],
   "source": [
    "data = pickle.loads(open(encoding_path+\"/encoding.pkl\", \"rb\").read())\n",
    "\n",
    "video_path = \".video/fast5-lq.mp4\" # Path to your video file\n",
    "output_path = \"./output/video/output_fast5.mp4\" # Path to save the output video\n",
    "vs = cv2.VideoCapture(video_path)\n",
    "print(f\"[INFO] processing video: {video_path}...\")\n",
    "\n",
    "# Get video properties for output video\n",
    "fps = int(vs.get(cv2.CAP_PROP_FPS))\n",
    "width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"[INFO] Video properties: FPS={fps}, Width={width}, Height={height}\")\n",
    "\n",
    "\n",
    "\n",
    "# Frame skipping configuration\n",
    "frame_skip = 3  # Process every 6th frame (adjust this value as needed)\n",
    "frame_count = 0\n",
    "output_fps = 20\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, output_fps, (width, height))\n",
    "# Variables to store last detection results\n",
    "last_boxes = []\n",
    "last_names = []\n",
    "\n",
    "while True:\n",
    "    # Grab the next frame from the video stream\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    # If the frame was not grabbed, then we have reached the end of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Only process every nth frame for face detection\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # --- YOUR LOGIC (applied to 'frame' instead of 'image') ---\n",
    "        # Convert the input frame from BGR to RGB\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect face locations and compute encodings\n",
    "        boxes = face_recognition.face_locations(rgb, model=\"hog\")\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        names = []\n",
    "\n",
    "        # Loop over the facial embeddings\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                counts = {}\n",
    "                for i in matchedIdxs:\n",
    "                    name = data[\"names\"][i]\n",
    "                    counts[name] = counts.get(name, 0) + 1\n",
    "                name = max(counts, key=counts.get)\n",
    "            \n",
    "            names.append(name)\n",
    "        \n",
    "        # Store the results for use in skipped frames\n",
    "        last_boxes = boxes\n",
    "        last_names = names\n",
    "    else:\n",
    "        # Use the last detection results for skipped frames\n",
    "        boxes = last_boxes\n",
    "        names = last_names\n",
    "\n",
    "    # Loop over the recognized faces to draw boxes and names\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# --- NEW: Clean up ---\n",
    "print(\"[INFO] cleaning up...\")\n",
    "vs.release()\n",
    "out.release()  # Release the video writer\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"[INFO] Output video saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
